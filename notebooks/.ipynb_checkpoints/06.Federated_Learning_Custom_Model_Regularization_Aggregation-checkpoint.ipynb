{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517dd5ed",
   "metadata": {},
   "source": [
    "### This example is almost equivalent to 05.Federated_Training_Inference. The ony difference is that in this notebook, we define our custom model, apply regularization during training and use a different federated aggregation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d8cf9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6941fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "parent = Path(os.path.abspath(\"\")).resolve().parents[0]\n",
    "if parent not in sys.path:\n",
    "    sys.path.insert(0, str(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb06673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a766f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.utils.data_utils import read_data, generate_time_lags, time_to_feature, handle_nans, to_Xy, \\\n",
    "    to_torch_dataset, to_timeseries_rep, assign_statistics, \\\n",
    "    to_train_val, scale_features, get_data_by_area, remove_identifiers, get_exogenous_data_by_area, handle_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66483b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.utils.train_utils import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a440899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.fl.defaults import create_regression_client\n",
    "from ml.fl.client_proxy import SimpleClientProxy\n",
    "from ml.fl.server.server import Server\n",
    "from ml.utils.helpers import accumulate_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402ccb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_path='../dataset/full_dataset.csv', # dataset\n",
    "\n",
    "    test_size=0.2, # validation size \n",
    "    targets=['rnti_count', 'rb_down', 'rb_up', 'down', 'up'], # the target columns\n",
    "    num_lags=10, # the number of past observations to feed as input\n",
    "\n",
    "    identifier='District', # the column name that identifies a bs\n",
    "\n",
    "    nan_constant=0, # the constant to transform nan values\n",
    "    x_scaler='minmax', # x_scaler\n",
    "    y_scaler='minmax', # y_scaler\n",
    "    outlier_detection=True, # whether to perform flooring and capping\n",
    "\n",
    "    criterion='mse', # optimization criterion, mse or l1\n",
    "    fl_rounds=30, # the number of federated rounds\n",
    "    fraction=1., # the percentage of available client to consider for random selection\n",
    "    aggregation=\"fednova\", # federated aggregation algorithm\n",
    "    epochs=3, # the number of maximum local epochs\n",
    "    lr=0.001, # learning rate\n",
    "    optimizer='adam', # the optimizer, it can be sgd or adam\n",
    "    batch_size=128, # the batch size to use\n",
    "    local_early_stopping=False, # whether to use early stopping\n",
    "    local_patience=50, # patience value for the early stopping parameter (if specified)\n",
    "    \n",
    "    max_grad_norm=1.0, # whether to clip grad norm\n",
    "    reg1=1e-8, # l1 regularization\n",
    "    reg2=1e-6, # l2 regularization\n",
    "\n",
    "    cuda=True, # whether to use gpu\n",
    "    \n",
    "    seed=0, # reproducibility\n",
    "\n",
    "    assign_stats=None, # whether to use statistics as exogenous data, [\"mean\", \"median\", \"std\", \"variance\", \"kurtosis\", \"skew\"]\n",
    "    use_time_features=False # whether to use datetime features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16dfd4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script arguments: Namespace(aggregation='fednova', assign_stats=None, batch_size=128, criterion='mse', cuda=True, data_path='../dataset/full_dataset.csv', epochs=3, fl_rounds=30, fraction=1.0, identifier='District', local_early_stopping=False, local_patience=50, lr=0.001, max_grad_norm=1.0, nan_constant=0, num_lags=10, optimizer='adam', outlier_detection=True, reg1=1e-08, reg2=1e-06, seed=0, targets=['rnti_count', 'rb_down', 'rb_up', 'down', 'up'], test_size=0.2, use_time_features=False, x_scaler='minmax', y_scaler='minmax')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Script arguments: {args}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e719537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if args.cuda and torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8973eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection specification\n",
    "if args.outlier_detection is not None:\n",
    "    outlier_columns = ['rb_down', 'rb_up', 'down', 'up']\n",
    "    outlier_kwargs = {\"ElBorn\": (10, 90), \"LesCorts\": (10, 90), \"PobleSec\": (5, 95)}\n",
    "    args.outlier_columns = outlier_columns\n",
    "    args.outlier_kwargs = outlier_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55014302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all():\n",
    "    # ensure reproducibility\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6476b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7ed9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessing():\n",
    "    \"\"\"Preprocess a given .csv\"\"\"\n",
    "    # read data\n",
    "    df = read_data(args.data_path)\n",
    "    # handle nans\n",
    "    df = handle_nans(train_data=df, constant=args.nan_constant,\n",
    "                     identifier=args.identifier)\n",
    "    # split to train/validation\n",
    "    train_data, val_data = to_train_val(df)\n",
    "    \n",
    "    # handle outliers (if specified)\n",
    "    if args.outlier_detection is not None:\n",
    "        train_data = handle_outliers(df=train_data, columns=args.outlier_columns,\n",
    "                                     identifier=args.identifier, kwargs=args.outlier_kwargs)\n",
    "    \n",
    "    # get X and y\n",
    "    X_train, X_val, y_train, y_val = to_Xy(train_data=train_data, val_data=val_data,\n",
    "                                          targets=args.targets)\n",
    "    \n",
    "    # scale X\n",
    "    X_train, X_val, x_scalers = scale_features(train_data=X_train, val_data=X_val,\n",
    "                                              scaler=args.x_scaler,\n",
    "                                              per_area=True, # the features are scaled locally\n",
    "                                              identifier=args.identifier)\n",
    "    # scale y\n",
    "    y_train, y_val, y_scalers = scale_features(train_data=y_train, val_data=y_val,\n",
    "                                              scaler=args.y_scaler, \n",
    "                                              per_area=True,\n",
    "                                              identifier=args.identifier)\n",
    "    \n",
    "    # generate time lags\n",
    "    X_train = generate_time_lags(X_train, args.num_lags)\n",
    "    X_val = generate_time_lags(X_val, args.num_lags)\n",
    "    y_train = generate_time_lags(y_train, args.num_lags, is_y=True)\n",
    "    y_val = generate_time_lags(y_val, args.num_lags, is_y=True)\n",
    "    \n",
    "    # get datetime features as exogenous data\n",
    "    date_time_df_train = time_to_feature(\n",
    "        X_train, args.use_time_features, identifier=args.identifier\n",
    "    )\n",
    "    date_time_df_val = time_to_feature(\n",
    "        X_val, args.use_time_features, identifier=args.identifier\n",
    "    )\n",
    "    \n",
    "    # get statistics as exogenous data\n",
    "    stats_df_train = assign_statistics(X_train, args.assign_stats, args.num_lags,\n",
    "                                       targets=args.targets, identifier=args.identifier)\n",
    "    stats_df_val = assign_statistics(X_val, args.assign_stats, args.num_lags, \n",
    "                                       targets=args.targets, identifier=args.identifier)\n",
    "    \n",
    "    # concat the exogenous features (if any) to a single dataframe\n",
    "    if date_time_df_train is not None or stats_df_train is not None:\n",
    "        exogenous_data_train = pd.concat([date_time_df_train, stats_df_train], axis=1)\n",
    "        # remove duplicate columns (if any)\n",
    "        exogenous_data_train = exogenous_data_train.loc[:, ~exogenous_data_train.columns.duplicated()].copy()\n",
    "        assert len(exogenous_data_train) == len(X_train) == len(y_train)\n",
    "    else:\n",
    "        exogenous_data_train = None\n",
    "    if date_time_df_val is not None or stats_df_val is not None:\n",
    "        exogenous_data_val = pd.concat([date_time_df_val, stats_df_val], axis=1)\n",
    "        exogenous_data_val = exogenous_data_val.loc[:, ~exogenous_data_val.columns.duplicated()].copy()\n",
    "        assert len(exogenous_data_val) == len(X_val) == len(y_val)\n",
    "    else:\n",
    "        exogenous_data_val = None\n",
    "        \n",
    "    return X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scalers, y_scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb403e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO logger 2024-04-27 22:22:06,992 | data_utils.py:383 | Observations info in ElBorn\n",
      "INFO logger 2024-04-27 22:22:06,993 | data_utils.py:384 | \tTotal number of samples:  4192\n",
      "INFO logger 2024-04-27 22:22:06,993 | data_utils.py:385 | \tNumber of samples for training: 3354\n",
      "INFO logger 2024-04-27 22:22:06,994 | data_utils.py:386 | \tNumber of samples for validation:  838\n",
      "INFO logger 2024-04-27 22:22:06,997 | data_utils.py:383 | Observations info in LesCorts\n",
      "INFO logger 2024-04-27 22:22:06,998 | data_utils.py:384 | \tTotal number of samples:  6892\n",
      "INFO logger 2024-04-27 22:22:06,998 | data_utils.py:385 | \tNumber of samples for training: 5514\n",
      "INFO logger 2024-04-27 22:22:06,999 | data_utils.py:386 | \tNumber of samples for validation:  1378\n",
      "INFO logger 2024-04-27 22:22:07,002 | data_utils.py:383 | Observations info in PobleSec\n",
      "INFO logger 2024-04-27 22:22:07,003 | data_utils.py:384 | \tTotal number of samples:  15927\n",
      "INFO logger 2024-04-27 22:22:07,003 | data_utils.py:385 | \tNumber of samples for training: 12742\n",
      "INFO logger 2024-04-27 22:22:07,003 | data_utils.py:386 | \tNumber of samples for validation:  3185\n",
      "INFO logger 2024-04-27 22:22:07,005 | data_utils.py:389 | Observations info using all data\n",
      "INFO logger 2024-04-27 22:22:07,006 | data_utils.py:390 | \tTotal number of samples:  27011\n",
      "INFO logger 2024-04-27 22:22:07,007 | data_utils.py:391 | \tNumber of samples for training: 21610\n",
      "INFO logger 2024-04-27 22:22:07,007 | data_utils.py:392 | \tNumber of samples for validation:  5401\n",
      "INFO logger 2024-04-27 22:22:07,007 | data_utils.py:118 | Using Flooring and Capping and with params: {'ElBorn': (10, 90), 'LesCorts': (10, 90), 'PobleSec': (5, 95)}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scalers, y_scalers = make_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cd61b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rb_up_var_lag-10</th>\n",
       "      <th>rb_up_lag-10</th>\n",
       "      <th>rb_down_var_lag-10</th>\n",
       "      <th>rb_down_lag-10</th>\n",
       "      <th>mcs_up_var_lag-10</th>\n",
       "      <th>mcs_up_lag-10</th>\n",
       "      <th>mcs_down_var_lag-10</th>\n",
       "      <th>mcs_down_lag-10</th>\n",
       "      <th>rnti_count_lag-10</th>\n",
       "      <th>up_lag-10</th>\n",
       "      <th>...</th>\n",
       "      <th>rb_down_var_lag-1</th>\n",
       "      <th>rb_down_lag-1</th>\n",
       "      <th>mcs_up_var_lag-1</th>\n",
       "      <th>mcs_up_lag-1</th>\n",
       "      <th>mcs_down_var_lag-1</th>\n",
       "      <th>mcs_down_lag-1</th>\n",
       "      <th>rnti_count_lag-1</th>\n",
       "      <th>up_lag-1</th>\n",
       "      <th>down_lag-1</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:16:00</th>\n",
       "      <td>3.143298e-08</td>\n",
       "      <td>0.014949</td>\n",
       "      <td>2.677239e-08</td>\n",
       "      <td>0.116414</td>\n",
       "      <td>0.207425</td>\n",
       "      <td>0.483274</td>\n",
       "      <td>0.796265</td>\n",
       "      <td>0.929664</td>\n",
       "      <td>0.227829</td>\n",
       "      <td>0.043207</td>\n",
       "      <td>...</td>\n",
       "      <td>2.890976e-08</td>\n",
       "      <td>0.145582</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>0.478785</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.916750</td>\n",
       "      <td>0.275640</td>\n",
       "      <td>0.051397</td>\n",
       "      <td>0.288248</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:18:00</th>\n",
       "      <td>4.439640e-08</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>2.795076e-08</td>\n",
       "      <td>0.145097</td>\n",
       "      <td>0.259314</td>\n",
       "      <td>0.530084</td>\n",
       "      <td>0.796778</td>\n",
       "      <td>0.914716</td>\n",
       "      <td>0.273796</td>\n",
       "      <td>0.067733</td>\n",
       "      <td>...</td>\n",
       "      <td>2.742117e-08</td>\n",
       "      <td>0.144613</td>\n",
       "      <td>0.242482</td>\n",
       "      <td>0.499756</td>\n",
       "      <td>0.783107</td>\n",
       "      <td>0.922241</td>\n",
       "      <td>0.274142</td>\n",
       "      <td>0.060095</td>\n",
       "      <td>0.286990</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:20:00</th>\n",
       "      <td>2.993595e-08</td>\n",
       "      <td>0.016880</td>\n",
       "      <td>2.825645e-08</td>\n",
       "      <td>0.130407</td>\n",
       "      <td>0.261772</td>\n",
       "      <td>0.512427</td>\n",
       "      <td>0.797310</td>\n",
       "      <td>0.921577</td>\n",
       "      <td>0.249107</td>\n",
       "      <td>0.045114</td>\n",
       "      <td>...</td>\n",
       "      <td>2.813661e-08</td>\n",
       "      <td>0.141717</td>\n",
       "      <td>0.241381</td>\n",
       "      <td>0.450879</td>\n",
       "      <td>0.800429</td>\n",
       "      <td>0.920308</td>\n",
       "      <td>0.269116</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.280625</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:22:00</th>\n",
       "      <td>5.382563e-08</td>\n",
       "      <td>0.026093</td>\n",
       "      <td>2.711694e-08</td>\n",
       "      <td>0.169723</td>\n",
       "      <td>0.320280</td>\n",
       "      <td>0.506925</td>\n",
       "      <td>0.782003</td>\n",
       "      <td>0.916003</td>\n",
       "      <td>0.315683</td>\n",
       "      <td>0.070769</td>\n",
       "      <td>...</td>\n",
       "      <td>2.869276e-08</td>\n",
       "      <td>0.173290</td>\n",
       "      <td>0.315197</td>\n",
       "      <td>0.495057</td>\n",
       "      <td>0.814955</td>\n",
       "      <td>0.917776</td>\n",
       "      <td>0.317020</td>\n",
       "      <td>0.078775</td>\n",
       "      <td>0.342454</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:24:00</th>\n",
       "      <td>5.922178e-08</td>\n",
       "      <td>0.028855</td>\n",
       "      <td>2.835084e-08</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>0.286799</td>\n",
       "      <td>0.497228</td>\n",
       "      <td>0.781283</td>\n",
       "      <td>0.919718</td>\n",
       "      <td>0.343507</td>\n",
       "      <td>0.078003</td>\n",
       "      <td>...</td>\n",
       "      <td>2.695933e-08</td>\n",
       "      <td>0.114517</td>\n",
       "      <td>0.267656</td>\n",
       "      <td>0.452835</td>\n",
       "      <td>0.792680</td>\n",
       "      <td>0.919174</td>\n",
       "      <td>0.226423</td>\n",
       "      <td>0.040565</td>\n",
       "      <td>0.228638</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rb_up_var_lag-10  rb_up_lag-10  rb_down_var_lag-10  \\\n",
       "time                                                                      \n",
       "2018-03-28 16:16:00      3.143298e-08      0.014949        2.677239e-08   \n",
       "2018-03-28 16:18:00      4.439640e-08      0.023976        2.795076e-08   \n",
       "2018-03-28 16:20:00      2.993595e-08      0.016880        2.825645e-08   \n",
       "2018-03-28 16:22:00      5.382563e-08      0.026093        2.711694e-08   \n",
       "2018-03-28 16:24:00      5.922178e-08      0.028855        2.835084e-08   \n",
       "\n",
       "                     rb_down_lag-10  mcs_up_var_lag-10  mcs_up_lag-10  \\\n",
       "time                                                                    \n",
       "2018-03-28 16:16:00        0.116414           0.207425       0.483274   \n",
       "2018-03-28 16:18:00        0.145097           0.259314       0.530084   \n",
       "2018-03-28 16:20:00        0.130407           0.261772       0.512427   \n",
       "2018-03-28 16:22:00        0.169723           0.320280       0.506925   \n",
       "2018-03-28 16:24:00        0.186603           0.286799       0.497228   \n",
       "\n",
       "                     mcs_down_var_lag-10  mcs_down_lag-10  rnti_count_lag-10  \\\n",
       "time                                                                           \n",
       "2018-03-28 16:16:00             0.796265         0.929664           0.227829   \n",
       "2018-03-28 16:18:00             0.796778         0.914716           0.273796   \n",
       "2018-03-28 16:20:00             0.797310         0.921577           0.249107   \n",
       "2018-03-28 16:22:00             0.782003         0.916003           0.315683   \n",
       "2018-03-28 16:24:00             0.781283         0.919718           0.343507   \n",
       "\n",
       "                     up_lag-10  ...  rb_down_var_lag-1  rb_down_lag-1  \\\n",
       "time                            ...                                     \n",
       "2018-03-28 16:16:00   0.043207  ...       2.890976e-08       0.145582   \n",
       "2018-03-28 16:18:00   0.067733  ...       2.742117e-08       0.144613   \n",
       "2018-03-28 16:20:00   0.045114  ...       2.813661e-08       0.141717   \n",
       "2018-03-28 16:22:00   0.070769  ...       2.869276e-08       0.173290   \n",
       "2018-03-28 16:24:00   0.078003  ...       2.695933e-08       0.114517   \n",
       "\n",
       "                     mcs_up_var_lag-1  mcs_up_lag-1  mcs_down_var_lag-1  \\\n",
       "time                                                                      \n",
       "2018-03-28 16:16:00          0.232918      0.478785            0.793296   \n",
       "2018-03-28 16:18:00          0.242482      0.499756            0.783107   \n",
       "2018-03-28 16:20:00          0.241381      0.450879            0.800429   \n",
       "2018-03-28 16:22:00          0.315197      0.495057            0.814955   \n",
       "2018-03-28 16:24:00          0.267656      0.452835            0.792680   \n",
       "\n",
       "                     mcs_down_lag-1  rnti_count_lag-1  up_lag-1  down_lag-1  \\\n",
       "time                                                                          \n",
       "2018-03-28 16:16:00        0.916750          0.275640  0.051397    0.288248   \n",
       "2018-03-28 16:18:00        0.922241          0.274142  0.060095    0.286990   \n",
       "2018-03-28 16:20:00        0.920308          0.269116  0.046993    0.280625   \n",
       "2018-03-28 16:22:00        0.917776          0.317020  0.078775    0.342454   \n",
       "2018-03-28 16:24:00        0.919174          0.226423  0.040565    0.228638   \n",
       "\n",
       "                     District  \n",
       "time                           \n",
       "2018-03-28 16:16:00    ElBorn  \n",
       "2018-03-28 16:18:00    ElBorn  \n",
       "2018-03-28 16:20:00    ElBorn  \n",
       "2018-03-28 16:22:00    ElBorn  \n",
       "2018-03-28 16:24:00    ElBorn  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c9073de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rnti_count</th>\n",
       "      <th>rb_down</th>\n",
       "      <th>rb_up</th>\n",
       "      <th>down</th>\n",
       "      <th>up</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:16:00</th>\n",
       "      <td>0.274142</td>\n",
       "      <td>0.144613</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.286990</td>\n",
       "      <td>0.060095</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:18:00</th>\n",
       "      <td>0.269116</td>\n",
       "      <td>0.141717</td>\n",
       "      <td>0.018685</td>\n",
       "      <td>0.280625</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:20:00</th>\n",
       "      <td>0.317020</td>\n",
       "      <td>0.173290</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.342454</td>\n",
       "      <td>0.078775</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:22:00</th>\n",
       "      <td>0.226423</td>\n",
       "      <td>0.114517</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.228638</td>\n",
       "      <td>0.040565</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 16:24:00</th>\n",
       "      <td>0.307914</td>\n",
       "      <td>0.164407</td>\n",
       "      <td>0.024169</td>\n",
       "      <td>0.327256</td>\n",
       "      <td>0.064402</td>\n",
       "      <td>ElBorn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rnti_count   rb_down     rb_up      down        up  \\\n",
       "time                                                                      \n",
       "2018-03-28 16:16:00    0.274142  0.144613  0.021526  0.286990  0.060095   \n",
       "2018-03-28 16:18:00    0.269116  0.141717  0.018685  0.280625  0.046993   \n",
       "2018-03-28 16:20:00    0.317020  0.173290  0.028488  0.342454  0.078775   \n",
       "2018-03-28 16:22:00    0.226423  0.114517  0.016597  0.228638  0.040565   \n",
       "2018-03-28 16:24:00    0.307914  0.164407  0.024169  0.327256  0.064402   \n",
       "\n",
       "                    District  \n",
       "time                          \n",
       "2018-03-28 16:16:00   ElBorn  \n",
       "2018-03-28 16:18:00   ElBorn  \n",
       "2018-03-28 16:20:00   ElBorn  \n",
       "2018-03-28 16:22:00   ElBorn  \n",
       "2018-03-28 16:24:00   ElBorn  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "814ccd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ElBorn': MinMaxScaler(),\n",
       "  'LesCorts': MinMaxScaler(),\n",
       "  'PobleSec': MinMaxScaler()},\n",
       " {'ElBorn': MinMaxScaler(),\n",
       "  'LesCorts': MinMaxScaler(),\n",
       "  'PobleSec': MinMaxScaler()})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scalers, y_scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c4f4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_postprocessing(X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scalers, y_scalers):\n",
    "    \"\"\"Make data ready to be fed into ml algorithms\"\"\"\n",
    "    # if there are more than one specified areas, get the data per area\n",
    "    if X_train[args.identifier].nunique() != 1:\n",
    "        area_X_train, area_X_val, area_y_train, area_y_val = get_data_by_area(X_train, X_val,\n",
    "                                                                              y_train, y_val, \n",
    "                                                                              identifier=args.identifier)\n",
    "    else:\n",
    "        area_X_train, area_X_val, area_y_train, area_y_val = None, None, None, None\n",
    "\n",
    "    # Get the exogenous data per area.\n",
    "    if exogenous_data_train is not None:\n",
    "        exogenous_data_train, exogenous_data_val = get_exogenous_data_by_area(exogenous_data_train,\n",
    "                                                                              exogenous_data_val)\n",
    "    # transform to np\n",
    "    if area_X_train is not None:\n",
    "        for area in area_X_train:\n",
    "            tmp_X_train, tmp_y_train, tmp_X_val, tmp_y_val = remove_identifiers(\n",
    "                area_X_train[area], area_y_train[area], area_X_val[area], area_y_val[area])\n",
    "            tmp_X_train, tmp_y_train = tmp_X_train.to_numpy(), tmp_y_train.to_numpy()\n",
    "            tmp_X_val, tmp_y_val = tmp_X_val.to_numpy(), tmp_y_val.to_numpy()\n",
    "            area_X_train[area] = tmp_X_train\n",
    "            area_X_val[area] = tmp_X_val\n",
    "            area_y_train[area] = tmp_y_train\n",
    "            area_y_val[area] = tmp_y_val\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        for area in exogenous_data_train:\n",
    "            exogenous_data_train[area] = exogenous_data_train[area].to_numpy()\n",
    "            exogenous_data_val[area] = exogenous_data_val[area].to_numpy()\n",
    "    \n",
    "    # remove identifiers from features, targets\n",
    "    X_train, y_train, X_val, y_val = remove_identifiers(X_train, y_train, X_val, y_val)\n",
    "    assert len(X_train.columns) == len(X_val.columns)\n",
    "    \n",
    "    num_features = len(X_train.columns) // args.num_lags\n",
    "    \n",
    "    # to timeseries representation\n",
    "    X_train = to_timeseries_rep(X_train.to_numpy(), num_lags=args.num_lags,\n",
    "                                            num_features=num_features)\n",
    "    X_val = to_timeseries_rep(X_val.to_numpy(), num_lags=args.num_lags,\n",
    "                                          num_features=num_features)\n",
    "    \n",
    "    if area_X_train is not None:\n",
    "        area_X_train = to_timeseries_rep(area_X_train, num_lags=args.num_lags,\n",
    "                                                     num_features=num_features)\n",
    "        area_X_val = to_timeseries_rep(area_X_val, num_lags=args.num_lags,\n",
    "                                                   num_features=num_features)\n",
    "    \n",
    "    # transform targets to numpy\n",
    "    y_train, y_val = y_train.to_numpy(), y_val.to_numpy()\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        exogenous_data_train_combined, exogenous_data_val_combined = [], []\n",
    "        for area in exogenous_data_train:\n",
    "            exogenous_data_train_combined.extend(exogenous_data_train[area])\n",
    "            exogenous_data_val_combined.extend(exogenous_data_val[area])\n",
    "        exogenous_data_train_combined = np.stack(exogenous_data_train_combined)\n",
    "        exogenous_data_val_combined = np.stack(exogenous_data_val_combined)\n",
    "        exogenous_data_train[\"all\"] = exogenous_data_train_combined\n",
    "        exogenous_data_val[\"all\"] = exogenous_data_val_combined\n",
    "    return X_train, X_val, y_train, y_val, area_X_train, area_X_val, area_y_train, area_y_val, exogenous_data_train, exogenous_data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "938e146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, client_X_train, client_X_val, client_y_train, client_y_val, exogenous_data_train, exogenous_data_val = make_postprocessing(X_train, X_val, y_train, y_val, exogenous_data_train, exogenous_data_val, x_scalers, y_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b2619b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Client: ElBorn\n",
      "X_train shape: (3344, 10, 11, 1), y_train shape: (3344, 5)\n",
      "X_val shape: (828, 10, 11, 1), y_val shape: (828, 5)\n",
      "\n",
      "Client: LesCorts\n",
      "X_train shape: (5504, 10, 11, 1), y_train shape: (5504, 5)\n",
      "X_val shape: (1368, 10, 11, 1), y_val shape: (1368, 5)\n",
      "\n",
      "Client: PobleSec\n",
      "X_train shape: (12732, 10, 11, 1), y_train shape: (12732, 5)\n",
      "X_val shape: (3175, 10, 11, 1), y_val shape: (3175, 5)\n"
     ]
    }
   ],
   "source": [
    "for client in client_X_train:\n",
    "    print(f\"\\nClient: {client}\")\n",
    "    print(f\"X_train shape: {client_X_train[client].shape}, y_train shape: {client_y_train[client].shape}\")\n",
    "    print(f\"X_val shape: {client_X_val[client].shape}, y_val shape: {client_y_val[client].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98cb5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dims(X_train, exogenous_data_train):\n",
    "    if args.model_name == \"mlp\":\n",
    "        input_dim = X_train.shape[1] * X_train.shape[2]\n",
    "    else:\n",
    "        input_dim = X_train.shape[2]\n",
    "    \n",
    "    if exogenous_data_train is not None:\n",
    "        if len(exogenous_data_train) == 1:\n",
    "            cid = next(iter(exogenous_data_train.keys()))\n",
    "            exogenous_dim = exogenous_data_train[cid].shape[1]\n",
    "        else:\n",
    "            exogenous_dim = exogenous_data_train[\"all\"].shape[1]\n",
    "    else:\n",
    "        exogenous_dim = 0\n",
    "    \n",
    "    return input_dim, exogenous_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef2bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_features=11, lags=10, out_dim=5,\n",
    "                 exogenous_dim: int = 0,\n",
    "                 in_channels=[1, 16],\n",
    "                 out_channels=[16, 32],\n",
    "                 kernel_sizes=[(2, 3), (5, 3)],\n",
    "                 pool_kernel_sizes=[(2, 1)]):\n",
    "        super(CNN, self).__init__()\n",
    "        assert len(in_channels) == len(out_channels) == len(kernel_sizes)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        self.num_lags = lags\n",
    "        self.num_features = num_features\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channels[0], out_channels=out_channels[0],\n",
    "                                     kernel_size=kernel_sizes[0], padding=\"same\")\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=in_channels[1], out_channels=out_channels[1],\n",
    "                                     kernel_size=kernel_sizes[1], padding=\"same\")\n",
    "        self.pool = torch.nn.AvgPool2d(kernel_size=pool_kernel_sizes[0])\n",
    "        kernel0, kernel1 = pool_kernel_sizes[-1][0], pool_kernel_sizes[-1][1]\n",
    "        self.fc = torch.nn.Linear(\n",
    "            in_features=(out_channels[1] * int(lags / kernel0) * int(num_features / kernel1)) + exogenous_dim,\n",
    "            out_features=out_dim)\n",
    "\n",
    "    def forward(self, x, exogenous_data=None, device=None, y_hist=None):\n",
    "        if len(x.shape) > 2:\n",
    "            x = x.view(x.size(0), x.size(3), x.size(1), x.size(2))\n",
    "        else:\n",
    "            x = x.view(x.size(0), 1, self.num_lags, self.num_features,)\n",
    "        x = self.conv1(x)  # [batch_size]\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # concatenate conv output with exogenous data\n",
    "        if exogenous_data is not None and len(exogenous_data) > 0:\n",
    "            x = torch.cat((x, exogenous_data), dim=1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d338b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83db8ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (activation): Tanh()\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(2, 3), stride=(1, 1), padding=same)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 3), stride=(1, 1), padding=same)\n",
       "  (pool): AvgPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0)\n",
       "  (fc): Linear(in_features=1760, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35f72279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, X_train, y_train, X_val, y_val, \n",
    "        exogenous_data_train=None, exogenous_data_val=None, \n",
    "        idxs=[8, 3, 1, 10, 9], # the indices of our targets in X\n",
    "        log_per=1,\n",
    "        client_creation_fn = None, # client specification\n",
    "        local_train_params=None, # local params\n",
    "        aggregation_params=None, # aggregation params\n",
    "        use_carbontracker=False\n",
    "       ):\n",
    "    # client creation definition\n",
    "    if client_creation_fn is None:\n",
    "        client_creation_fn = create_regression_client\n",
    "    # local params\n",
    "    if local_train_params is None:\n",
    "        local_train_params = {\n",
    "            \"epochs\": args.epochs, \"optimizer\": args.optimizer, \"lr\": args.lr,\n",
    "            \"criterion\": args.criterion, \"early_stopping\": args.local_early_stopping,\n",
    "            \"patience\": args.local_patience, \"device\": device,\n",
    "            \"reg1\": args.reg1, \"reg2\": args.reg2,\n",
    "            \"max_grad_norm\": args.max_grad_norm\n",
    "        }\n",
    "    \n",
    "    train_loaders, val_loaders = [], []\n",
    "    \n",
    "    # get data per client\n",
    "    for client in X_train:\n",
    "        if client == \"all\":\n",
    "            continue\n",
    "        if exogenous_data_train is not None:\n",
    "            tmp_exogenous_data_train = exogenous_data_train[client]\n",
    "            tmp_exogenous_data_val = tmp_exogenous_data_val[client]\n",
    "        else:\n",
    "            tmp_exogenous_data_train = None\n",
    "            tmp_exogenous_data_val = None\n",
    "    \n",
    "        num_features = len(X_train[client][0][0])\n",
    "        \n",
    "        # to torch loader\n",
    "        train_loaders.append(\n",
    "            to_torch_dataset(\n",
    "                X_train[client], y_train[client],\n",
    "                num_lags=args.num_lags,\n",
    "                num_features=num_features,\n",
    "                exogenous_data=tmp_exogenous_data_train,\n",
    "                indices=idxs,\n",
    "                batch_size=args.batch_size,\n",
    "                shuffle=False\n",
    "            )\n",
    "        )\n",
    "        val_loaders.append(\n",
    "            to_torch_dataset(\n",
    "                X_val[client], y_val[client],\n",
    "                num_lags=args.num_lags,\n",
    "                exogenous_data=tmp_exogenous_data_val,\n",
    "                indices=idxs,\n",
    "                batch_size=args.batch_size,\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "        )\n",
    "        \n",
    "    # create clients with their local data\n",
    "    cids = [k for k in X_train.keys() if k != \"all\"]\n",
    "    clients = [\n",
    "        client_creation_fn(\n",
    "            cid=cid, # client id\n",
    "            model=model, # the global model\n",
    "            train_loader=train_loader, # the local train loader\n",
    "            test_loader=val_loader, # the local val loader\n",
    "            local_params=local_train_params # local parameters\n",
    "        )\n",
    "        for cid, train_loader, val_loader in zip(cids, train_loaders, val_loaders)\n",
    "    ]\n",
    "    \n",
    "    # represent clients to server\n",
    "    client_proxies = [\n",
    "        SimpleClientProxy(cid, client) for cid, client in zip(cids, clients)\n",
    "    ]\n",
    "    \n",
    "    # represent the server\n",
    "    server = Server(\n",
    "        client_proxies=client_proxies, # the client representations\n",
    "        aggregation=args.aggregation, # the aggregation algorithm\n",
    "        aggregation_params=aggregation_params, # aggregation specific params\n",
    "        local_params_fn=None, # we can change the local params on demand\n",
    "    )\n",
    "    # Note that the client manager instance will be initialized automatically. You can define your own client manager.\n",
    "\n",
    "    # train with FL\n",
    "    model_params, history = server.fit(args.fl_rounds, args.fraction, use_carbontracker=use_carbontracker)\n",
    "    \n",
    "    params_dict = zip(model.state_dict().keys(), model_params)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    model = copy.deepcopy(model)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de341140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# federated local params\n",
    "local_train_params = {\n",
    "            \"epochs\": args.epochs, \"optimizer\": args.optimizer, \"lr\": args.lr,\n",
    "            \"criterion\": args.criterion, \"early_stopping\": args.local_early_stopping,\n",
    "            \"patience\": args.local_patience, \"device\": device,\n",
    "            \"reg1\": args.reg1, \"reg2\": args.reg2,\n",
    "            \"max_grad_norm\": args.max_grad_norm\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6fef34",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "global_model, history = fit(\n",
    "    model,\n",
    "    client_X_train,\n",
    "    client_y_train, \n",
    "    client_X_val, \n",
    "    client_y_val, \n",
    "    local_train_params=local_train_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdc4fa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13ada4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1695e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def transform_preds(y_pred_train, y_pred_val):\n",
    "    if not isinstance(y_pred_train, np.ndarray):\n",
    "        y_pred_train = y_pred_train.cpu().numpy()\n",
    "    if not isinstance(y_pred_val, np.ndarray):\n",
    "        y_pred_val = y_pred_val.cpu().numpy()\n",
    "    return y_pred_train, y_pred_val\n",
    "\n",
    "def round_predictions(y_pred_train, y_pred_val, dims):\n",
    "    # round to closest integer\n",
    "    if dims is None or len(dims) == 0:\n",
    "        return y_pred_train, y_pred_val\n",
    "    for dim in dims:\n",
    "        y_pred_train[:, dim] = np.rint(y_pred_train[:, dim])\n",
    "        y_pred_val[:, dim] = np.rint(y_pred_val[:, dim])\n",
    "    return y_pred_train, y_pred_val\n",
    "\n",
    "def inverse_transform(y_train, y_val, y_pred_train, y_pred_val,\n",
    "                     y_scaler=None, \n",
    "                     round_preds=False, dims=None):\n",
    "    y_pred_train, y_pred_val = transform_preds(y_pred_train, y_pred_val)\n",
    "    \n",
    "    if y_scaler is not None:\n",
    "        y_train = y_scaler.inverse_transform(y_train)\n",
    "        y_val = y_scaler.inverse_transform(y_val)\n",
    "        y_pred_train = y_scaler.inverse_transform(y_pred_train)\n",
    "        y_pred_val = y_scaler.inverse_transform(y_pred_val)\n",
    "    \n",
    "    # to zeroes\n",
    "    y_pred_train[y_pred_train < 0.] = 0.\n",
    "    y_pred_val[y_pred_val < 0.] = 0.\n",
    "    \n",
    "    if round_preds:\n",
    "        y_pred_train, y_pred_val = round_predictions(y_pred_train, y_pred_val, dims)\n",
    "    \n",
    "    return y_train, y_val, y_pred_train, y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a7e86",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def make_plot(y_true, y_pred, \n",
    "              title, \n",
    "              feature_names=None, \n",
    "              client=None):\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(y_pred.shape[1])]\n",
    "    assert len(feature_names) == y_pred.shape[1]\n",
    "\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.ticklabel_format(style='plain')\n",
    "        plt.plot(y_true[:, i], label=\"Actual\")\n",
    "        plt.plot(y_pred[:, i], label=\"Predicted\")\n",
    "        if client is not None:\n",
    "            plt.title(f\"[{client} {title}] {feature_names[i]} prediction\")\n",
    "        else:\n",
    "            plt.title(f\"[{title}] {feature_names[i]} prediction\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55843a4e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model, # the global model\n",
    "    client_X_train, # train data per client\n",
    "    client_y_train,\n",
    "    client_X_val, # val data per client\n",
    "    client_y_val,\n",
    "    exogenous_data_train, # exogenous data per client\n",
    "    exogenous_data_val,\n",
    "    y_scalers, # the scaler used to transform the targets\n",
    "    idxs=[8, 3, 1, 10, 9],\n",
    "    apply_round=True, # round to closest integer\n",
    "    round_dimensions=[0, 3, 4], # the dimensions to apply rounding\n",
    "    plot=True, # plot predictions\n",
    "):\n",
    "    # load per client data to torch\n",
    "    train_loaders, val_loaders = [], []\n",
    "    \n",
    "    # get data per client\n",
    "    for client in client_X_train:\n",
    "        if client == \"all\":\n",
    "            continue\n",
    "        assert client in list(y_scalers.keys())\n",
    "        if exogenous_data_train is not None:\n",
    "            tmp_exogenous_data_train = exogenous_data_train[client]\n",
    "            tmp_exogenous_data_val = exogenous_data_val[client]\n",
    "        else:\n",
    "            tmp_exogenous_data_train = None\n",
    "            tmp_exogenous_data_val = None\n",
    "    \n",
    "        num_features = len(client_X_train[client][0][0])\n",
    "        \n",
    "        # to torch loader\n",
    "        train_loaders.append(\n",
    "            to_torch_dataset(\n",
    "                client_X_train[client], client_y_train[client],\n",
    "                num_lags=args.num_lags,\n",
    "                num_features=num_features,\n",
    "                exogenous_data=tmp_exogenous_data_train,\n",
    "                indices=idxs,\n",
    "                batch_size=1,\n",
    "                shuffle=False\n",
    "            )\n",
    "        )\n",
    "        val_loaders.append(\n",
    "            to_torch_dataset(\n",
    "                client_X_val[client], client_y_val[client],\n",
    "                num_lags=args.num_lags,\n",
    "                exogenous_data=tmp_exogenous_data_val,\n",
    "                indices=idxs,\n",
    "                batch_size=1,\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "        )\n",
    "        \n",
    "    # get client ids\n",
    "    cids = [k for k in client_X_train.keys() if k != \"all\"]\n",
    "        \n",
    "    # predict per client using the global model\n",
    "    y_preds_train, y_preds_val = dict(), dict()\n",
    "    for cid, train_loader, val_loader in zip(cids, train_loaders, val_loaders):\n",
    "        print(f\"Prediction on {cid}\")\n",
    "        train_mse, train_rmse, train_mae, train_r2, train_nrmse, y_pred_train = test(\n",
    "            model, train_loader, None, device=device\n",
    "        )\n",
    "        val_mse, val_rmse, val_mae, val_r2, val_nrmse, y_pred_val = test(\n",
    "            model, val_loader, None, device=device\n",
    "        )\n",
    "        y_preds_train[cid] = y_pred_train\n",
    "        y_preds_val[cid] = y_pred_val\n",
    "    \n",
    "    for cid in cids:\n",
    "        y_train, y_val = client_y_train[cid], client_y_val[cid]\n",
    "        y_pred_train, y_pred_val = y_preds_train[cid], y_preds_val[cid]\n",
    "        \n",
    "        y_scaler = y_scalers[cid]\n",
    "        y_train, y_val, y_pred_train, y_pred_val = inverse_transform(\n",
    "            y_train, y_val, y_pred_train, y_pred_val,\n",
    "            y_scaler, round_preds=apply_round, dims=round_dimensions\n",
    "        )\n",
    "        train_mse, train_rmse, train_mae, train_r2, train_nrmse, train_res_per_dim = accumulate_metric(\n",
    "            y_train, y_pred_train, True, return_all=True\n",
    "        )\n",
    "        val_mse, val_rmse, val_mae, val_r2, val_nrmse, val_res_per_dim = accumulate_metric(\n",
    "            y_val, y_pred_val, True, return_all=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFinal Prediction on {cid} (Inference Stage)\")\n",
    "        print(f\"[Train]: mse: {train_mse}, \"\n",
    "              f\"rmse: {train_rmse}, mae {train_mae}, r2: {train_r2}, nrmse: {train_nrmse}\")\n",
    "        print(f\"[Val]: mse: {val_mse}, \"\n",
    "              f\"rmse: {val_rmse}, mae {val_mae}, r2: {val_r2}, nrmse: {val_nrmse}\\n\\n\")\n",
    "        \n",
    "        if plot:\n",
    "            make_plot(y_train, y_pred_train, title=\"Train\", feature_names=args.targets, client=cid)\n",
    "            make_plot(y_val, y_pred_val, title=\"Val\", feature_names=args.targets, client=cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca7aac",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inference(\n",
    "    global_model,\n",
    "    client_X_train, \n",
    "    client_y_train,\n",
    "    client_X_val, \n",
    "    client_y_val,\n",
    "    exogenous_data_train, \n",
    "    exogenous_data_val,\n",
    "    y_scalers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4582d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fe3b4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "a39106e1a9d6d153b7400628e7589ff266b5caee5b0db427f0903be982155882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
